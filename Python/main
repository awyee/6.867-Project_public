# 5th December
# Final 6.867 Project

from matplotlib import pyplot as plt
import numpy as np
import pickle
import sys
import xlrd
from sklearn.model_selection import train_test_split
import pandas as pd
from collections import OrderedDict

# File Paths
CONSOLIDATED_LABELS_PATH = '/Users/Nic/Dropbox (MIT)/6.867/6.867 Project/Consolidated_Labels.xlsx'





class CreateDataSet:
    """ This class creates the dataset separated into Testing, Training and Validation

        - Data = Testing + (Train + Validation)
            - e.g. Data= 0.1 + (0.8 +0.2)

     """

    def __init__(self, name, consolidated_labels_path='/Users/Nic/Dropbox (MIT)/6.867/6.867 Project/Consolidated_Labels.xlsx', testing_frac=0.1, training_frac=0.80 ):

        self.testing_frac = testing_frac
        self.training_frac = training_frac
        self.consolidated_labels_path = consolidated_labels_path

        self.testing = pd.DataFrame
        self.validation = pd.DataFrame
        self.training = pd.DataFrame

        # Extract Data From WorkSheet
        workbook = xlrd.open_workbook(self.consolidated_labels_path)
        # Now create a dictionary for the sheets within the workbook
        sheets = {'A': workbook.sheet_by_name('A'),
                  'B': workbook.sheet_by_name('B'),
                  'C': workbook.sheet_by_name('C'),
                  'D': workbook.sheet_by_name('D'),
                  'E': workbook.sheet_by_name('E'),
                  'F': workbook.sheet_by_name('F')}

        frames_test = []
        frames_train = []
        frames_validate = []

        for sheet in sheets:
            t_test, t_train, t_validate = self.split_to_ttv(sheets[sheet])
            frames_test.append(t_test)
            frames_train.append(t_train)
            frames_validate.append(t_validate)

        self.testing = pd.concat(frames_test)
        self.training = pd.concat(frames_train)
        self.validation = pd.concat(frames_validate)


    def save_data_set(self):
        pickle.dump(self, open(self.name, 'wb')) # wb: write and binary

    def split_to_ttv(self, sheet):

        x = pd.DataFrame(sheet._cell_values)
        test = x.sample(frac=self.testing_frac)

        rest = x.drop(test.index)

        train = rest.sample(frac=self.training_frac)
        validate = rest.drop(train.index)

        return test, train, validate

    def extract_eatures(self):
        self.NormaliseFeatures

    def normalise_features(self):


def load_data_set(filename='dataset.p'):
    '''
      This loads the split data labels
    '''
    return pickle.load(open(filename, 'rb')) # wb: read and binary


# RUN
x = CreateDataSet(CONSOLIDATED_LABELS_PATH,'name', testing_frac=0.1,training_frac=0.8)